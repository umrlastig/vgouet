<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>LASTIG - Valerie Gouet-Brunet - Homepage</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i">
  <link rel="stylesheet" href="vendor/fontawesome-free/css/all.min.css">
  <link rel="stylesheet" href="vendor/academicons/css/academicons.min.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.9/dist/css/bootstrap-select.min.css">

  <!-- Custom styles for this template -->
  <link href="css/animate.css" rel="stylesheet">
  <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">
  <link href="css/resume.css" rel="stylesheet">
  <link href="css/extras.css" rel="stylesheet">

  <!-- scripts on load -->
  <script src="vendor/d3/d3.min.js"></script>
  <script src="js/reviewing.js" charset="utf-8"></script>
  <script src="js/hal.js" charset="utf-8"></script>

</head>

<body id="page-top" onload="reviewingVis('reviewing.json'); getPublicationsAuthor('valerie-gouet-brunet');">

<!--   <body id="page-top" onload="reviewingVis('reviewing.json');getPublicationsAuthor('valerie-gouet-brunet');getJournalPublicationsAuthor('valerie-gouet-brunet');getConfPublicationsAuthor('valerie-gouet-brunet');getBookPublicationsAuthor('valerie-gouet-brunet');getOtherPublicationsAuthor('valerie-gouet-brunet');">  -->

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <select class="selectpicker" data-width="fit">
      <option data-content='<span class="flag-icon flag-icon-us"></span>'>English</option>
      <option data-content='<span class="flag-icon flag-icon-fr"></span>'>Français</option>
    </select>
    <a class="nav-link text-muted subheading" href="https://umrlastig.github.io">LaSTIG</a> 
    <a class="nav-link text-muted subheading" href="/acte">ACTE</a>
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Valérie Gouet-Brunet</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/photo_valerie.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger lang-en" href="#about">About</a>
          <a class="nav-link js-scroll-trigger lang-fr" href="#about">Présentation</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger lang-en" href="#interest">Research areas</a>
          <a class="nav-link js-scroll-trigger lang-fr" href="#interest">Sujets de recherche</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger lang-en" href="#publications">Publications</a>
          <a class="nav-link js-scroll-trigger lang-fr" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger lang-en" href="#projects">Projects</a>
          <a class="nav-link js-scroll-trigger lang-fr" href="#projects">Projets</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger lang-en" href="#experience">Experience</a>
          <a class="nav-link js-scroll-trigger lang-fr" href="#experience">Parcours professionnel</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger lang-en" href="#other">Miscellaneous</a>
          <a class="nav-link js-scroll-trigger lang-fr" href="#other">Divers</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0 m-0">

    <section class="resume-section mt-0 pt-0 p-lg-5 d-flex" id="about">
      <div class="w-100">
        <h1 class="mb-0">
          <span class="text-primary"><font size="+2">Valérie Gouet-Brunet</font></span>
        </h1>
        <div class="subheading mb-3">IGN · 73 avenue de Paris · 94165 Saint-Mandé Cedex FRANCE · (+33)1 43 98 62 10 · <a>vale<!--anti@spam.fr!-->rie.gouet@ign.fr</a></div>
        <p class="lead lang-en"><font size="+0"><b>ICT senior scientist specialized in Content-based Image Retrieval, Computer Vision and Multimedia, with current applications to the valorization of cultural and natural iconographic Heritage</font></b></p>
        <p class="lead mb-4 lang-en" align="justify"><font size="+0"><b><i>Short bio.</i></b> Valérie Gouet-Brunet has been research director (DR1) of the French Ministry of Ecology (MTES) since 2012. She carries out her research at the French mapping agency (IGN - National Institute for Geographical and Forest Information), within the <a href="https://umrlastig.github.io" target=new>LaSTIG</a> laboratory, and at the University <a href="https://www.univ-gustave-eiffel.fr" target=new> Gustave Eiffel</a>. Within the <a href="" target=new>ACTE</a> research group, she is in charge of researches on the description by content, matching and indexing of large-scale and long-term multimedia collections, with a focus on images and their structuring, exploration and spatialization with application to cultural and natural heritage. For 4 years until 2018, she headed the MATIS laboratory (35 members) at IGN, specialized in mathematics and computer science applied to photogrammetry, computer vision and remote sensing for multi-sensor and multi-source imaging. She obtained a PhD in Computer Vision in 2000 from the University of Montpellier II (France) on the area of color image matching with application to intermediate view synthesis, and an habilitation to conduct research at the Pierre and Marie Curie University (France) in 2008 on the area of content-based structuring of collections of still and animated images. V. Gouet-Brunet has supervised more than fifty PhD students and researchers and participated in or coordinated some twenty partnership projects of various kinds (French national ANR and FUI projects, European projects, bilateral industrial contracts, international research collaborations). Currently, she is coordinating the <a href="http://alegoria.ign.fr/" target=new>ALEGORIA</a> project (French ANR 2018-2021), is member of the steering committee of the French Association for pattern recognition and interpretation (<a href="http://www.afrif.asso.fr" target=new>AFRIF</a>), of the board of the European association <a href="https://www.timemachine.eu/" target=new>Time Machine Organisation</a>, and of the working group <a href="https://www.notre-dame.science" target=new>"Digital data"</a> of the scientific site for the restoration of Notre-Dame de Paris.</font></p>
        <p class="lead lang-fr"><font size="+0"><b>Directrice de recherche (DR1 MTES) dans le domaine des STIC, spécialisée en indexation d'images par contenu, vision par ordinateur et multimédia, avec comme principale application actuelle la valorisation du patrimoine iconographique culturel et naturel</font></b></p>
        <p class="lead mb-4 lang-fr" align="justify"><font size="+0"><b><i>Short bio.</i></b> Valérie Gouet-Brunet est directrice de recherche (DR1) du Ministère de la Transition Ecologique et Solidaire (MTES) depuis 2012, en poste à l'IGN (Institut National de l'Information Géographique et Forestière). Elle effectue ses recherches au sein du laboratoire <a href="https://umrlastig.github.io" target=new>LaSTIG</a> de l'IGN, rattaché à l'université <a href="https://www.univ-gustave-eiffel.fr" target=new> Gustave Eiffel</a>. Au sein de l'équipe <a href="" target=new>ACTE</a>, elle est en charge de recherches sur la description par le contenu visuel, l'appariement et l'indexation de collections multimédia à large échelle et à long terme, avec un focus sur les contenus iconographiques et leur structuration, exploration et spatialisation pour le patrimoine culturel et naturel. Pendant 4 ans jusqu'en 2018, elle a dirigé le laboratoire MATIS (35 membres) de l'IGN, spécialisé dans les mathématiques et l'informatique appliquées à  la photogrammétrie, la vision par ordinateur et la télédétection pour l'imagerie multi-capteur et multi-source. Elle a obtenu un doctorat en vision par ordinateur en 2000 à l'Université de Montpellier II sur le thème de l'appariement d'images couleur avec application à la synthèse de vues intermédiaires, puis une HdR à l'Université Pierre et Marie Curie en 2008 sur le thème de la structuration par contenu de collections d'images fixes et animées. V. Gouet-Brunet a supervisé plus d'une cinquantaine de doctorants et chercheurs, et participé à ou coordonné une vingtaine de projets partenariaux de différentes natures (ANR, FUI, projets Européens, contrats industriels bilatéraux, collaborations de recherche internationales). Actuellement, elle coordonne le projet ANR <a href="http://alegoria.ign.fr/" target=new>ALEGORIA</a> (ANR AAPG 2018-2021), est membre du conseil d'administration de l'<a href="http://www.afrif.asso.fr" target=new> AFRIF</a>, du comité de pilotage de l'association européenne <a href="https://www.timemachine.eu/" target=new>Time Machine Organisation</a>, et participe au groupe de travail <a href="https://www.notre-dame.science" target=new>"Données numériques"</a> du chantier scientifique pour la restauration de Notre-Dame de Paris.</font></p>
        <div class="social-icons">
          <a href="https://cv.archives-ouvertes.fr/valerie-gouet-brunet" target=new>
            <i class="ai"><img src="img/icons/hal-b2.svg" width=45px/></i>
          </a>
          <a href="https://fr.linkedin.com/in/valerie-gouet-brunet-969917a" target=new>
            <i class="fab fa-linkedin-in"></i>
          </a>
          <a href="https://scholar.google.fr/citations?hl=fr&user=mqq6zX4AAAAJ" target=new>
            <i class="ai ai-google-scholar"></i>
          </a>
          <a href="https://orcid.org/0000-0003-3666-5146" target=new>
            <i class="ai ai-orcid"></i>
          </a>
          <a href="#" target=new>
            <i class="ai ai-researchgate"></i>
          </a>
        </div>
      </div>
    </section>

<!-- ******************************* RESEARCH ACTIVITIES ******************************* -->

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content" id="interest">
      <div class="w-75">
        <h3 class="mb-3 lang-en">Current research areas and applications</h3>
        <h3 class="mb-3 lang-fr">Sujets de recherche actuels et applications</h3>
        <h5 class="mb-5 lang-en">Content-based image indexing and retrieval in challenging conditions</h5>
        <h5 class="mb-5 lang-fr">Indexation et recherche d'images par contenu visuel en conditions difficiles</h5>
        <div class="row">
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/image_desc.png" alt="" />
                  <div class="portfolio-desc d-flex align-center position-absolute h-100 w-100">
                    <div class="folio-info my-auto w-100 text-center">
                      <h6 class="lang-en"><font color="white"> Description of image contents at large scale in challenging conditions</font></h6>
                      <h6 class="lang-fr"><font color="white">Description des contenus image à large échelle en conditions difficiles</font></h6>
                    </div>
                  </div>
                </div>
          </article>
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/saliency.png" alt="" />
                  <div class="portfolio-desc d-flex align-center position-absolute h-100 w-100">
                    <div class="folio-info my-auto w-100 text-center">
                      <h6 class="lang-en"><font color="white">Visual saliency in urban contents</font></h6>
                      <h6 class="lang-fr"><font color="white">Saillance visuelle en imagerie urbaine</font></h6>
                    </div>
                  </div>
                </div>
          </article>
          </div>
          <h4 class="mt-5 mb-5 lang-en">Fusion of modalities for image matching, classification and indexing</h4>
          <h4 class="mt-5 mb-5 lang-fr">Fusion de modalités pour l'appariement, la classification et l'indexation d'images</h4>
          <div class="row">
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/modalities.png" alt="" />
                  <div class="portfolio-desc align-center position-absolute h-100 w-100">
                    <div class="folio-info w-100 text-center">
                      <h6 class="lang-en"><font color="white">Learning geometric modalities for vision-based retrieval in challenging conditions</font></h6>
                      <h6 class="lang-fr"><font color="white">Apprentissage de modalités géométriques pour la recherche d'images par contenu en conditions difficiles</font></h6>
                    </div>
                  </div>
                </div>
          </article>
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/embedded.png" alt="" />
                  <div class="portfolio-desc align-center position-absolute h-100 w-100">
                    <div class="folio-info w-100 text-center">
                      <h6 class="lang-en"><font color="white">Combination of visual and inertial sensors for tracking on embedded systems</font></h6>
                      <h6 class="lang-fr"><font color="white">Combinaison d'informations visuelles et inertielles pour le suivi embarqué</font></h6>
                    </div>
                  </div>
                </div>
          </article>
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/Forest_seg.png" alt="" />
                  <div class="portfolio-desc align-center position-absolute h-100 w-100">
                    <div class="folio-info w-100 text-center">
                      <h6 class="lang-en"><font color="white">Land use classification by joint analysis of superspectral and LiDAR imagery</font></h6>
                      <h6 class="lang-fr"><font color="white">Classification OCS par analyse conjointe d'images superspectrales et LiDAR</font></h6>
                    </div>
                  </div>
                </div>
          </article>
          </div>
          <h4 class="mt-5 mb-5 lang-en">Applications</h4>
          <h4 class="mt-5 mb-5 lang-fr">Applications</h4>
          <div class="row">
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/ND_CBIR.png" alt="" />
                  <div class="portfolio-desc align-center position-absolute h-100 w-100">
                    <div class="folio-info w-100 text-center">
                      <h6 class="lang-en"><font color="white">Structuring and interlinking of cultural and natural iconographic heritage</font></h6>
                      <h6 class="lang-fr"><font color="white">Structuration et interconnexions du patrimoine iconographique culturel et naturel</font></h6>
                    </div>
                  </div>
                </div>
          </article>
          <article class="col-md-6 col-lg-4">
                <div class="portfolio-item d-block mx-auto">
                  <img class="img-fluid" src="img/ltloc.png" alt="" />
                  <div class="portfolio-desc align-center position-absolute h-100 w-100">
                    <div class="folio-info w-100 text-center">
                      <h6 class="lang-en"><font color="white">Long-term vision-based localization</font></h6>
                      <h6 class="lang-fr"><font color="white">Localisation basée vision à long terme</font></h6>
                    </div>
                  </div>
                </div>
          </article>
        </div>
      </div>
    </section>

<!-- ******************************* PUBLICATIONS ******************************* -->

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="publications">
      <div class="w-100">
        <h3 class="mb-3">Publications</h3>

		<span id="pubACL"><div class="subheading mb-3 mt-3 lang-en">International journals / Revues internationales [ACL(N)]</div></span>
        
        <span id="pubACLN"><div class="subheading mb-3 mt-3 lang-en">National journals / Revues nationales [ACL(N)]</div></span>
        
        <span id="pubASCL"><div class="subheading mb-3 mt-3 lang-en">Non-reviewed journals / Revues sans comité de lecture [ASCL]</div></span>
        
        <span id="pubACTI"><div class="subheading mb-3 mt-3 lang-en">International conferences / Conférences internationales [ACTI]</div></span>
        
        <span id="pubACTN"><div class="subheading mb-3 mt-3 lang-en">National conferences / Conférences nationales [ACTN]</div></span>
        
        <span id="pubCOM"><div class="subheading mb-3 mt-3 lang-en">Conferences without proceedings / Communications orales sans actes [COM]</div></span>
        
        <span id="pubOS"><div class="subheading mb-3 mt-3 lang-en">Books and Chapters / Livres et chapitres de livre [OS]</div></span>
        
        <span id="pubDO"><div class="subheading mb-3 mt-3 lang-en">Book or journal editors / Directions d'ouvrages ou de revues [DO]</div></span>
        
        <span id="pubAFF"><div class="subheading mb-3 mt-3 lang-en">Posters / Posters [AFF]</div></span>
        
        <span id="pubAP"><div class="subheading mb-3 mt-3 lang-en">Preprints / Rapports [AP]</div></span>
        
        <span id="pubTH"><div class="subheading mb-3 mt-3 lang-en">Dissertations / Thèse et HDR [TH]</div></span>
        
        <span id="pubINV"><div class="subheading mb-3 mt-3 lang-en">Invited Talks / Conférences invitées [INV]</div></span>
        
        <span id="pubPV"><div class="subheading mb-3 mt-3 lang-en">Popularization / Vulgarisation [PV]</div></span>

        <!-- provide a subset of the publications based on a keyword -->
        <!--
        <span id="pubGeneralisation"><div class="subheading mb-3 mt-3">Généralisation</div></span>
	<script> getKeywordPublicationsAuthorStartYear('guillaume-touya', 'Généralisation', 2006, "pubGeneralisation"); </script>
        -->
      </div>
    </section>


<!-- ******************************* PROJECTS ******************************* -->

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items" id="projects">
      <div class="w-100">
          <h3 class="mb-3 lang-en">Ongoing and past projects at IGN</h3>
          <h3 class="mb-3 lang-fr">Projets en cours et passés à l'IGN</h3>
        <div class="row projects">
        <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/IGN_frise_Stereopolis.jpg" alt="" class="iconL2">
              </div>
              <h4 class="heading">ON STAGE 3D</h4>
              <p class="description lang-en">cONtent-based STructuring of pAris photoGraphic hEritage in 3D<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>ANRT CIFRE Ville de Paris 2020-2023</b></p>
              <p class="description lang-fr">cONtent-based STructuring of pAris photoGraphic hEritage in 3D<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>ANRT CIFRE Ville de Paris 2020-2023</b></p>
            </div>
          </div>
        <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/timemachine.jpg" alt="" class="iconL1">
              </div>
              <h4 class="heading"><a href="https://www.timemachine.eu/" target=new>Time Machine</a></h4>
              <p class="description lang-en"> &laquo; The Big Data of the past for the Future of Europe &raquo;<br><img src="img/icons/Europe.svg" alt="" width=24px><br><b> From 2019 <br>(former CSA H2020 2019-2020)</b></p>
              <p class="description lang-fr"> &laquo; Les big data du passé pour l'avenir de l'Europe &raquo;<br><img src="img/icons/Europe.svg" alt="" width=24px><br><b> Depuis 2019 <br>(anciennement CSA H2020 2019-2020)</b></p>
            </div>
        </div>
        <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_ALEGORIA_75.png" alt="" class="iconL2">
              </div>
              <h4 class="heading"><a href="http://alegoria.ign.fr" target=new>ALEGORIA</a></h4>
              <p class="description lang-en">&laquo; Advanced Linking and Exploitation of diGitized geOgRaphic Iconographic heritAge &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>ANR AAPG 2018-2021</b></p>
              <p class="description lang-fr">&laquo; structurAtion et vaLorisation du patrimoinE géoGraphique icOnogRaphIque démAtérialisé &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>ANR AAPG 2018-2021</b></p>
            </div>
          </div>
          <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_AC.png" alt="" class="iconL2">
              </div>
              <h4 class="heading"><a href="#" target=new>Archival City</a></h4>
              <p class="description lang-en">&laquo; Understanding and exploitation of urban archives &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>Tremplin i-Site FUTURE 2019-2023 </b></p>
              <p class="description lang-fr">&laquo; Compréhension et exploitation des archives urbaines &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>Tremplin de l'i-Site FUTURE 2019-2023 </b></p>
            </div>
          </div>
          <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_Platinum.png" alt="" class="iconL2">
              </div>
              <h4 class="heading"><a href="http://platinum.projets.litislab.fr" target=new>pLaTINUM</a></h4>
              <p class="description lang-en">&laquo; Long Term MappINg for Urban Mobility &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b> ANR AAPG 2015-2019 </b></p>
              <p class="description lang-fr">&laquo; Cartographie à long terme pour la mobilité urbaine &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b> ANR AAPG 2015-2019 </b></p>
            </div>
          </div>
          <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_Things2Do.png" alt="" class="iconL1">
              </div>
              <h4 class="heading"><a href="http://things2do.space.com.ro" target=new>Thing2Do</a></h4>
              <p class="description">&laquo; THIN but Great Silicon 2 Design Objects &raquo;<br><img src="img/icons/Europe.svg" alt="" width=24px><br><b>H2020 Ket ENIAC 2014-2018</b></p>
            </div>
          </div>
          <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_POEME.png" alt="" class="iconL1">
              </div>
              <h4 class="heading"><a href="https://anr.fr/en/funded-projects-and-impact/funded-projects/project/funded/project/b2d9d3668f92a3b9fbbf7866072501ef-37f3473a5f/?tx_anrprojects_funded%5Bcontroller%5D=Funded&cHash=eb327f02768110addefb0c44c33147ae" target=new>POEME</a></h4>
              <p class="description lang-en">&laquo; Photographic cOntents Exploration through iMmersive Environment &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b> ANR CONTINT 2013-2016</b></p>
              <p class="description lang-fr">&laquo; Exploration de contenus photographiques à travers des environnements immersifs &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b> ANR CONTINT 2013-2016</b></p>
            </div>
          </div>
          <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_DESCRIBE.png" alt="" class="iconL2">
              </div>
              <h4 class="heading"><a href="https://anr.fr/en/funded-projects-and-impact/funded-projects/project/funded/project/b2d9d3668f92a3b9fbbf7866072501ef-65b18baae8/?tx_anrprojects_funded%5Bcontroller%5D=Funded&cHash=a550abd0d0a463382f8a54b12ccfea0d" target=new>DESCRiBE</a></h4>
              <p class="description lang-en">&laquo; Online event detection in video sequences using structural and Bayesian approaches &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>ANR ASTRID 2013-2015</b></p>
              <p class="description lang-fr">&laquo; Détection d'évènement en ligne dans les séquences vidéo à partir d'approches structurelles et bayésiennes &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b>ANR ASTRID 2013-2015</b></p>
            </div>
          </div>
          <div class="col-md-4">
            <div class="project">
              <div class="icon-holder">
                <img src="img/icons/logo_Terramobilita.png" alt="" class="iconL2">
              </div>
              <h4 class="heading"><a href="http://www.terramobilita.fr" target=new>Terra Mobilita</a></h4>
              <p class="description lang-en">&laquo; 3D mapping of urban roads and public spaces, accessibility and soft traffic &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b> FUI 2011-2015</b></p>
              <p class="description lang-fr">&laquo; Cartographie 3D de la voirie et de l’espace public urbains, accessibilité et circulations douces &raquo;<br><img src="img/icons/fr.svg" alt="" width=16px><br><b> FUI 2011-2015</b></p>
            </div>
          </div>
        </div>
      </div>
      <div class="cut cut-bottom"></div>
    </section>

<!-- ******************************* EXPERIENCE ******************************* -->

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="experience">
      <div class="w-100">
        <h3 class="mb-5 lang-en">Experience and milestones</h3>
        <h3 class="mb-5 lang-fr">Parcours et faits marquants</h3>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Research director MTES (DR1 level)</h5>
            <h5 class="mb-0 lang-fr">Directrice de recherche MTES (DR1)</h5>
            <div class="subheading mb-3">LaSTIG Lab, IGN - France</div>
          </div>
          <div class="resume-date text-md-right"><span class="text-primary">2019 - Present</span></div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Head of MATIS Lab</h5>
            <h5 class="mb-0 lang-fr">Responsable du laboratoire MATIS</h5>
            <div class="subheading mb-3">MATIS Lab, IGN - France</div>
          </div>
          <div class="resume-date text-md-right"><span class="text-primary">2014 - 2017</span></div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Research director MTES (DR2 level)</h5>
            <h5 class="mb-0 lang-fr">Directrice de recherche MTES (DR2)</h5>
            <div class="subheading mb-3">MATIS Lab, IGN - France</div>
            <p>
            <b>Research topics:</b> content-based image indexing and retrieval applied to street-view and aeriel imagery<br>
            <b>Head</b> of the research group ATOLL (Image matching and structuring at large scale)</p>
          </div>
          <div class="resume-date text-md-right"><span class="text-primary">Oct. 2012 - 2018</span></div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Habilitation to direct researches</h5>
            <h5 class="mb-0 lang-fr">Habilitation à diriger des recherches</h5>
            <div class="subheading mb-3">Pierre et Marie Curie University - France</div>
            <p><b>Title:</b> Content-based structuring of still and animated images collections</p>
          </div>
          <div class="resume-date text-md-right"><span class="text-primary">02/12/2008</span></div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Assistant professor</h5>
            <h5 class="mb-0 lang-fr">Maître de conférences</h5>
            <div class="subheading mb-3">CEDRIC Lab / Computer Science Dept, Cnam Paris - France</div>
            <p>
            <b>Research topics</b>: multimedia databases, content-based image retrieval at large scale<br>			<b>Teaching</b>: databases, image analysis and computer vision in the Computer Science department of Cnam<br>			<b>Recipient of awards:</b> PEDR (2005-2009) and PES (rank A, 2009-2012)</p>
          </div>
          <div class="resume-date text-md-right"><span class="text-primary">Sept. 2002 - 2012</span></div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Associate researcher</h5>
            <h5 class="mb-0 lang-fr">Chercheur associé (ingénieur expert)</h5>
            <div class="subheading mb-3">Imedia research group, Inria - France</div>
              <p>Researches in content-based image retrieval with application to video copy detection</p>
            </div>
            <div class="resume-date text-md-right"><span class="text-primary">Sept. 2002 - 2007</span></div>
         </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">Post-doc fellow</h5>
            <h5 class="mb-0 lang-fr">Post-doctorat</h5>
            <div class="subheading mb-3">Imedia research group, Inria - France</div>
              <p>Researches in content-based image retrieval with a focus on local descriptors</p>
            </div>
            <div class="resume-date text-md-right"><span class="text-primary">2000 - 2002</span></div>
          </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-3">
          <div class="resume-content">
            <h5 class="mb-0 lang-en">PhD thesis</h5>
            <h5 class="mb-0 lang-fr">Thèse de doctorat</h5>
            <div class="subheading mb-3">LGI2P Lab, Ecole des Mines d'Alès - France</div>
              <p>
              <b>Title:</b> Color image matching - Application to the synthesis of novel views<br>
              <b>Supervisors:</b> Jean-Claude Bajard (Université de Montpellier II), Philippe Montesinos (EMA)<br>
              </p>
            </div>
            <div class="resume-date text-md-right"><span class="text-primary">1996 - 2000<br>Defense: 25/10/2000</span></div>
          </div>
          
        </div>
    </section>


<!-- ******************************* MISCELLANEOUS ******************************* -->

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="other">
      <div class="w-100">
        <h3 class="mb-3 lang-en">Miscellaneous</h3>
        <h3 class="mb-3 lang-fr">Divers</h3>
        
        <h5 class="mb-3 mt-5 lang-en">Ongoing PhD and researchers supervision</h5>
        <h5 class="mb-3 mt-5 lang-fr">Directions de thèse et supervision de chercheurs en cours</h5>
		<ul class="fa-ul mb-0">
		    <li><i class="fa-li fa fa-square"></i>
            <p class="lang-en"><b>Laura Willot</b>: thesis co-supervised with Livio de Luca (MAP, CNRS/MC) and Dan Vodislav (ETIS, CY Cergy Paris Université), on the automatic classification of photographic images for spatio-temporal monitoring of restoration sites (ClaS-Ter project, 2021-2024)</p>
            <p class="lang-fr"><b>Laura Willot</b> : thèse co-encadrée avec Livio de Luca (MAP, CNRS/MC) et Dan Vodislav (ETIS, CY Cergy Paris Université), sur la classification automatique d’images photographiques pour le suivi spatio-temporel des chantiers de restauration (projet ClaS-Ter, 2021-2024)</p>
            </li>
            <li><i class="fa-li fa fa-square"></i>
            <li><i class="fa-li fa fa-square"></i>
            <p class="lang-en"><b>Emile Blettery</b>: thesis on the structuring of heritage iconographic contents by exploiting 2D and 3D information (ON STAGE 3D project, 2020-2023)</p>
            <p class="lang-fr"><b>Emile Blettery</b> : thèse sur la structuration de fonds iconographiques patrimoniauxpar exploitation d'un référentiel géographique 2D et 3D (projet ON STAGE 3D, 2020-2023)</p>
            </li>
        </ul>

        <h5 class="mb-3 mt-5 lang-en">Past PhD and researchers supervision at IGN (from 2012)</h5>
        <h5 class="mb-3 mt-5 lang-fr">Directions de thèse et supervision de chercheurs passées à l'IGN (depuis 2012)</h5>
		<ul class="fa-ul mb-0">
		    <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Dimitri Gominski</b>: thesis co-directed with Liming Chen (Centrale Lyon/LIRIS) on the description, matching and indexing of multi-date and multi-source image contents (ANR ALEGORIA and DGA projects, 2018-2021)</p>
            <p class="lang-fr"><b>Dimitri Gominski</b> : thèse co-dirigée avec Liming Chen (Centrale Lyon/LIRIS) sur la description, appariement et indexation de contenus image multi-date et multi-source (projets ANR ALEGORIA et DGA, 2018-2021)</p>
            </li>

		    <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Imane Salhi</b>: thesis co-supervised with Erwan Piriou, Maroun Ojail (CEA-LIST/L3A) and Martyna Poreba on On-board intelligent camera for object tracking on a mobile platform (2017-2020)</p>
            <p class="lang-fr"><b>Imane Salhi</b> : thèse co-encadrée avec Erwan Piriou, Maroun Ojail (CEA-LIST/L3A) et Martyna Poreba sur la mise en oeuvre d'une caméra intelligente embarquée pour le suivi d'objet sur plateforme mobile (2017-2020)</p>
            </li>
            
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Margarita Khokhlova</b>: post-doc supervised with Liming Chen (Centrale Lyon/LIRIS) and Nathalie Abadie (LaSTIG) on machine learning and multi-modal image indexing (ALEGORIA project, 2018-2021)</p>
            <p class="lang-fr"><b>Margarita Khokhlova</b> : post-doctorante supervisée avec Liming Chen (Centrale Lyon/LIRIS) et Nathalie Abadie (LaSTIG) sur l'indexation d'images multi-modale par apprentissage profond (projet ALEGORIA, 2018-2021)</p>
            </li>

            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Nathan Piasco</b>: thesis co-directed with Cedric Demonceaux (Bourgogne University/LE2I) and supervised by Desire Sidibe (Bourgogne University/LE2I) on vision-based localization with discriminative features from heterogeneous visual data (pLaTINUM project, 2016-2019)</p>
            <p class="lang-fr"><b>Nathan Piasco</b> : thèse co-dirigée avec Cédric Demonceaux (Université de Bourgogne/LE2I) et co-encadrée par Désiré Sidibé (Université de Bourgogne/LE2I) sur la localisation basée vision à partir de caractéristiques discriminantes issues de données visuelles hétérogènes (projet pLaTINUM, 2016-2019)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Kamel Guissous</b>: thesis on visual saliency in urban imagery (Things2Do project, 2015-2019)</p>
            <p class="lang-fr"><b>Kamel Guissous</b> : thèse sur la saillance visuelle en imagerie urbaine (projet Things2Do, 2015-2019)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Neelanjan Bhowmik</b>: thesis on multi-descriptor retrieval in digitalized photographs collections (POEME project, 2014-2017)</p>
            <p class="lang-fr"><b>Neelanjan Bhowmik</b> : thèse sur la recherche multi-descripteur dans les collections de photographies numérisées (projet POEME, 2014-2017)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Clement Dechesne</b>: thesis supervised by Clement Mallet and Arnaud Le Bris on the extraction of forest features by joint analysis of superspectral or hyperspectral imagery and 3D lidar data (2014-2017)</p>
            <p class="lang-fr"><b>Clément Déchesne</b>, thèse co-encadrée par Clément Mallet et Arnaud Le Bris sur l'extraction de caractéristiques forestières par analyse conjointe de données image superspectrales/hyperspectrales et LiDAR (2014-2017)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Ali Seba</b>: post-doc supervised with Ewelina Rupnik (IGN) on pose estimation in challenging conditions (Things2Do and SmartCity Vision projects, 2017-2019)</p>
            <p class="lang-fr"><b>Ali Seba</b> : post-doctorante supervisée avec Ewelina Rupnik (IGN) sur l'estimation de poseen conditions difficiles (projets Things2Do et SmartCity Vision, 2017-2019)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Li Weng</b>: post-doc supervised with Bahman Soheilian (IGN) on camera localizationwith large-scale semantic object signatures (Things2Do project, 2016-2017)</p>
            <p class="lang-fr"><b>Li Weng</b> : post-doctorante supervisée avec Bahman Soheilian (IGN) sur la localisation de caméra à partir de signatures d'objets sémantiques à large échelle (projet Things2Do, 2016-2017)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Bastien Hell</b>: engineer supervised with David Vandergucht (IGN) on the development of an object detector in images for semantic-based localization (Things2Do project, 2016-2017)</p>
            <p class="lang-fr"><b>Bastien Hell</b>, ingénieur supervisé avec David Vandergucht (IGN) sur le développement d’un détecteur d’objets dans des images pour la localisation basée sur l’analyse sémantique de l’environnement (projet Things2Do, 2016-2017)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>David Vandergucht</b>: engineer and project manager supervised with Bahman Soheilian (IGN) on visual-based localization on embedded targets and at large scale (Things2Do project, 2015-2017)</p>
            <p class="lang-fr"><b>David Vandergucht</b>, ingénieur chef de projet supervisé avec Bahman Soheilian (IGN) sur la localisation basée image sur cible embarquée et à large échelle (projet Things2Do, 2015-2017)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Lijun Wei</b>: post-doc supervised with Bahman Soheilian (IGN) on the detection and matching of visual landmarks applied to visual-based localization (Terra Mobilita project, 2013-2015)</p>
            <p class="lang-fr"><b>Lijun Wei</b> : post-doctorante supervisée avec Bahman Soheilian (IGN) sur la détection et miseen correspondance d'amers visuels appliquées à la localisation basée image (projet Terra Mobilita, 2013-2015)</p>
            </li>
            <li><i class="fa-li fa fa-check-square"></i>
            <p class="lang-en"><b>Abdalbassir Abou-Elailah</b>: post-doc supervised with Isabelle Bloch (Telecom ParisTech) on the description of spatial relationships between complex visual entities represented with sparse sets (DESCRiBE project, 2013-2014)</p>
            <p class="lang-fr"><b>Abdalbassir Abou-Elailah</b> : post-doctorant supervisé avec Isabelle Bloch (Telecom ParisTech) sur la description et modélisation des relations spatiales entre entités visuelles complexes représentées par des ensembles épars (projet DESCRiBE, 2013-2014)</p>
            </li>
        </ul>
        
        <h5 class="mb-3 mt-5 lang-en">Teaching</h5>
		<h5 class="mb-3 mt-5 lang-fr">Enseignement</h5>
		<ul class="fa-ul mb-0">
            <li><i class="fa-li fa fa-square"></i>
            <p class="lang-en">From 2012, lectures in the Master's degree in photogrammetry, positioning and deformation measurement at <a href="http://www.ensg.eu/?lang=en" target=new>ENSG</a></p>
            <p class="lang-fr">Depuis 2012, cours magistraux dans le Mastère PPMD (Photogrammétrie, Positionnement et Mesure des  Déformations à l'<a href="http://www.ensg.eu/?lang=en" target=new>ENSG</a></p>
            </li>
            	<ul class="fa-ul mb-0">
		             <li><i class="fa-li fa fa-circle"></i> 
		             <p class="m-0 p-0 lang-en">Extraction of local features in image contents</p>
		             <p class="m-0 p-0 lang-fr">Extraction de caractéristiques locales dans les contenus image</p>
		             <li><i class="fa-li fa fa-circle"></i> 
		             <p class="m-0 p-0 lang-en">Image matching</p>
		             <p class="m-0 p-0 lang-fr">Appariement d'images</p>
		             <li><i class="fa-li fa fa-circle"></i> 
		             <p class="m-0 p-0 lang-en">Content-based image indexing and retrieval</p>
		             <p class="m-0 p-0 lang-fr">Indexation et recherche d'images par contenu visuel</p>
                </ul>
           <li><i class="fa-li fa fa-square"></i>
           <p class="mt-3 lang-en">From 2005 to 2018, lectures on multimedia databases in the Master ISI, Paris-Dauphine University</p>
           <p class="mt-3 lang-fr">Entre 2005 et 2018, cours magistraux sur les bases de données multimédia dans le Master ISI, Université Paris-Dauphine</p>
          <li><i class="fa-li fa fa-square"></i>
		  <p class="lang-en">From 2005 to 2018, lectures on Acquisition and management of digital multimedia content, in the Master SIAW, Marne-la-Vallée University</p>
		  <p class="lang-fr">Entre 2005 et 2018, cours magistraux sur l'acquisition et les traitement de contenus multimedia numériques, dans le Master SIAW, Université Marne-la-Vallée</p>
       </ul>
       
       <h5 class="mb-3 mt-5 lang-en">Personal</h5>
	   <h5 class="mb-3 mt-5 lang-fr">Perso</h5>
		<ul class="fa-ul mb-0">
          <li><i class="fa-li fa fa-square"></i>
            <p class="lang-en">Married, mom of two (2010 and 2015)</p>
            <p class="lang-fr">Mariée, deux enfants (2010 et 2015)</p>
          <li><i class="fa-li fa fa-square"></i>
            <p class="lang-en">Die-hard Parisian city dweller who regularly takes refuge in Limousin and Normandy</p>
            <p class="lang-fr">Citadine parisienne invétérée qui se réfugie régulièrement en Limousin et en Normandie</p>
          <li><i class="fa-li fa fa-square"></i>
		    <p class="lang-en">Passionate about travel, photography, architecture, 1950-1970 design, pop art, street art and Louis de Funes</p>
		    <p class="lang-fr">Passionnée par les voyages, la photographie, l'architecture, le design 1950-1970, le pop art, le street art et Louis de Funès</p>
       </ul>
    </section>

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
  <script src="vendor/jquery.isotope.min.js"></script>
  <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.9/dist/js/bootstrap-select.min.js"></script>
  <!-- Custom scripts for this template -->
  <script src="js/resume.js"></script>

</body>

</html>
